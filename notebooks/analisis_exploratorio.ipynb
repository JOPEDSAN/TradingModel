{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ed2cec",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos Financieros\n",
    "\n",
    "Este notebook realiza un análisis exploratorio de datos financieros obtenidos de Yahoo Finance, incluyendo:\n",
    "- Visualización de precios históricos\n",
    "- Cálculo y visualización de indicadores técnicos\n",
    "- Análisis de correlaciones entre diferentes activos\n",
    "- Identificación de patrones en series temporales financieras\n",
    "\n",
    "El objetivo es preparar los datos para su uso en modelos predictivos para trading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ad561",
   "metadata": {},
   "source": [
    "## 1. Importación de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Para cálculos financieros\n",
    "import talib as ta  # Requiere instalación separada: pip install TA-Lib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Configuración de visualización\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set(style='darkgrid', palette='muted', font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Formato para fechas\n",
    "date_format = mdates.DateFormatter('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f646699",
   "metadata": {},
   "source": [
    "## 2. Descarga de Datos Históricos\n",
    "\n",
    "Obtendremos datos históricos para una selección de activos financieros:\n",
    "- Índices principales (S&P 500, Dow Jones, NASDAQ)\n",
    "- Grandes empresas tecnológicas (Apple, Microsoft, Google, etc.)\n",
    "- ETFs importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d0d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los tickers a analizar\n",
    "tickers = [\n",
    "    # Índices principales\n",
    "    \"^GSPC\",  # S&P 500\n",
    "    \"^DJI\",   # Dow Jones\n",
    "    \"^IXIC\",  # NASDAQ\n",
    "    \n",
    "    # Grandes tecnológicas\n",
    "    \"AAPL\",   # Apple\n",
    "    \"MSFT\",   # Microsoft\n",
    "    \"GOOGL\",  # Alphabet (Google)\n",
    "    \"AMZN\",   # Amazon\n",
    "    \"META\",   # Meta (Facebook)\n",
    "    \"TSLA\",   # Tesla\n",
    "    \n",
    "    # ETFs importantes\n",
    "    \"SPY\",    # SPDR S&P 500 ETF\n",
    "    \"QQQ\",    # Invesco QQQ (Nasdaq-100)\n",
    "    \"VTI\",    # Vanguard Total Stock Market ETF\n",
    "]\n",
    "\n",
    "# Definir el rango de fechas (2 años de datos)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365 * 2)\n",
    "\n",
    "# Función para descargar datos\n",
    "def download_data(ticker_list, start, end):\n",
    "    data_dict = {}\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        print(f\"Descargando datos para {ticker}...\")\n",
    "        try:\n",
    "            data = yf.download(ticker, start=start, end=end)\n",
    "            if not data.empty:\n",
    "                data_dict[ticker] = data\n",
    "                print(f\"  ✓ {len(data)} filas descargadas\")\n",
    "            else:\n",
    "                print(f\"  ✗ No se encontraron datos\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {str(e)}\")\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# Descargar datos\n",
    "data_dict = download_data(tickers, start_date, start_date + timedelta(days=30))\n",
    "\n",
    "# Comprobar si el directorio de datos existe\n",
    "if not os.path.exists('../data'):\n",
    "    os.makedirs('../data')\n",
    "\n",
    "# Guardar algunos ejemplos para futuras referencias\n",
    "for ticker, data in list(data_dict.items())[:3]:  # Solo guardar 3 ejemplos\n",
    "    data.to_csv(f\"../data/{ticker.replace('^', '')}_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369b86f",
   "metadata": {},
   "source": [
    "## 3. Exploración de Datos\n",
    "\n",
    "Realizaremos un análisis exploratorio básico de los datos descargados para entender su estructura y características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa89899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar un ticker para análisis detallado (usaremos S&P 500)\n",
    "ticker_example = \"^GSPC\"\n",
    "if ticker_example in data_dict:\n",
    "    df = data_dict[ticker_example]\n",
    "    \n",
    "    # Información básica del DataFrame\n",
    "    print(f\"Datos para {ticker_example} (S&P 500):\")\n",
    "    print(f\"Período: {df.index[0].strftime('%Y-%m-%d')} a {df.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Número de días de trading: {len(df)}\")\n",
    "    print(\"\\nPrimeras filas:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # Estadísticas descriptivas\n",
    "    print(\"\\nEstadísticas descriptivas:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    # Verificar valores nulos\n",
    "    print(\"\\nValores nulos por columna:\")\n",
    "    display(df.isnull().sum())\n",
    "else:\n",
    "    print(f\"No se encontraron datos para {ticker_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c33011",
   "metadata": {},
   "source": [
    "## 4. Visualización de Precios Históricos\n",
    "\n",
    "Visualizaremos los precios históricos para entender las tendencias y patrones en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0923227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar precios\n",
    "def plot_price_history(data, ticker_name, title=None):\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    # Graficar precio de cierre\n",
    "    ax.plot(data.index, data['Close'], linewidth=2, label='Precio de Cierre')\n",
    "    \n",
    "    # Agregar promedio móvil de 50 días\n",
    "    data['MA50'] = data['Close'].rolling(window=50).mean()\n",
    "    ax.plot(data.index, data['MA50'], linewidth=1.5, label='Media Móvil (50 días)', \n",
    "            linestyle='--', color='orange')\n",
    "    \n",
    "    # Agregar promedio móvil de 200 días\n",
    "    data['MA200'] = data['Close'].rolling(window=200).mean()\n",
    "    ax.plot(data.index, data['MA200'], linewidth=1.5, label='Media Móvil (200 días)', \n",
    "            linestyle='--', color='red')\n",
    "    \n",
    "    # Configurar el gráfico\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=16)\n",
    "    else:\n",
    "        ax.set_title(f'Precio Histórico de {ticker_name}', fontsize=16)\n",
    "    \n",
    "    ax.set_xlabel('Fecha', fontsize=12)\n",
    "    ax.set_ylabel('Precio ($)', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Formatear eje x para fechas\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Graficar para algunos ejemplos\n",
    "for ticker in list(data_dict.keys())[:3]:  # Solo mostrar 3 ejemplos\n",
    "    name = ticker.replace('^', '')  # Quitar ^ para índices\n",
    "    if ticker in [\"^GSPC\", \"^DJI\", \"^IXIC\"]:\n",
    "        names = {\"^GSPC\": \"S&P 500\", \"^DJI\": \"Dow Jones\", \"^IXIC\": \"NASDAQ\"}\n",
    "        name = names[ticker]\n",
    "    \n",
    "    if ticker in data_dict:\n",
    "        fig = plot_price_history(data_dict[ticker], name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f9158",
   "metadata": {},
   "source": [
    "## 5. Cálculo de Indicadores Técnicos\n",
    "\n",
    "Calcularemos varios indicadores técnicos comúnmente utilizados en análisis financiero:\n",
    "- RSI (Índice de Fuerza Relativa)\n",
    "- MACD (Convergencia/Divergencia de Medias Móviles)\n",
    "- Bandas de Bollinger\n",
    "- Retornos diarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular indicadores técnicos\n",
    "def calculate_indicators(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Retornos diarios\n",
    "    df['Return'] = df['Close'].pct_change() * 100  # Porcentaje\n",
    "    df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1)) * 100\n",
    "    \n",
    "    # Medias móviles\n",
    "    df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['SMA_200'] = df['Close'].rolling(window=200).mean()\n",
    "    \n",
    "    # RSI (14 días)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD\n",
    "    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
    "    \n",
    "    # Bandas de Bollinger (20 días, 2 desviaciones estándar)\n",
    "    df['BB_Middle'] = df['Close'].rolling(window=20).mean()\n",
    "    df['BB_Std'] = df['Close'].rolling(window=20).std()\n",
    "    df['BB_Upper'] = df['BB_Middle'] + 2 * df['BB_Std']\n",
    "    df['BB_Lower'] = df['BB_Middle'] - 2 * df['BB_Std']\n",
    "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
    "    \n",
    "    # Volatilidad (desviación estándar de los retornos en 20 días)\n",
    "    df['Volatility_20'] = df['Log_Return'].rolling(window=20).std()\n",
    "    \n",
    "    # Volumen relativo\n",
    "    df['Volume_SMA_20'] = df['Volume'].rolling(window=20).mean()\n",
    "    df['Rel_Volume'] = df['Volume'] / df['Volume_SMA_20']\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# Calcular indicadores para un ejemplo (S&P 500)\n",
    "ticker_example = \"^GSPC\"\n",
    "if ticker_example in data_dict:\n",
    "    df_indicators = calculate_indicators(data_dict[ticker_example])\n",
    "    print(\"Indicadores técnicos calculados:\")\n",
    "    display(df_indicators.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a7913",
   "metadata": {},
   "source": [
    "## 6. Visualización de Indicadores Técnicos\n",
    "\n",
    "Visualizaremos los indicadores técnicos calculados para entender su comportamiento y relación con el precio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ecb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar indicadores para S&P 500\n",
    "if ticker_example in data_dict:\n",
    "    df = df_indicators.copy()\n",
    "    \n",
    "    # Crear figura con subplots\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(16, 20), gridspec_kw={'height_ratios': [3, 1, 1, 1]})\n",
    "    \n",
    "    # 1. Precio y Bandas de Bollinger\n",
    "    axs[0].plot(df.index, df['Close'], label='Precio de Cierre', color='blue', linewidth=1.5)\n",
    "    axs[0].plot(df.index, df['BB_Upper'], label='Banda Superior', color='red', linestyle='--', alpha=0.7)\n",
    "    axs[0].plot(df.index, df['BB_Middle'], label='Media Móvil (20 días)', color='green', linestyle='--', alpha=0.7)\n",
    "    axs[0].plot(df.index, df['BB_Lower'], label='Banda Inferior', color='red', linestyle='--', alpha=0.7)\n",
    "    axs[0].fill_between(df.index, df['BB_Upper'], df['BB_Lower'], color='gray', alpha=0.1)\n",
    "    axs[0].set_title('S&P 500 con Bandas de Bollinger', fontsize=15)\n",
    "    axs[0].set_ylabel('Precio ($)', fontsize=12)\n",
    "    axs[0].legend(loc='upper left')\n",
    "    axs[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Volumen\n",
    "    axs[1].bar(df.index, df['Volume'], color='blue', alpha=0.7, label='Volumen')\n",
    "    axs[1].plot(df.index, df['Volume_SMA_20'], color='red', linewidth=1.5, label='Media Móvil (20 días)')\n",
    "    axs[1].set_ylabel('Volumen', fontsize=12)\n",
    "    axs[1].legend(loc='upper left')\n",
    "    axs[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. RSI\n",
    "    axs[2].plot(df.index, df['RSI_14'], color='purple', linewidth=1.5)\n",
    "    axs[2].axhline(y=70, color='red', linestyle='--', alpha=0.7)\n",
    "    axs[2].axhline(y=30, color='green', linestyle='--', alpha=0.7)\n",
    "    axs[2].fill_between(df.index, df['RSI_14'], 70, where=(df['RSI_14'] >= 70), color='red', alpha=0.3)\n",
    "    axs[2].fill_between(df.index, df['RSI_14'], 30, where=(df['RSI_14'] <= 30), color='green', alpha=0.3)\n",
    "    axs[2].set_ylabel('RSI', fontsize=12)\n",
    "    axs[2].set_ylim(0, 100)\n",
    "    axs[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. MACD\n",
    "    axs[3].plot(df.index, df['MACD'], color='blue', linewidth=1.5, label='MACD')\n",
    "    axs[3].plot(df.index, df['MACD_Signal'], color='red', linewidth=1.5, label='Señal')\n",
    "    axs[3].bar(df.index, df['MACD_Hist'], color='green', alpha=0.5, label='Histograma')\n",
    "    axs[3].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axs[3].set_ylabel('MACD', fontsize=12)\n",
    "    axs[3].set_xlabel('Fecha', fontsize=12)\n",
    "    axs[3].legend(loc='upper left')\n",
    "    axs[3].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Formatear eje x para fechas en todos los subplots\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_major_formatter(date_format)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987831ae",
   "metadata": {},
   "source": [
    "## 7. Análisis de Correlación entre Activos\n",
    "\n",
    "Analizaremos las correlaciones entre diferentes activos para entender sus relaciones y posibles oportunidades de diversificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los precios de cierre de todos los activos\n",
    "close_prices = pd.DataFrame()\n",
    "\n",
    "for ticker, data in data_dict.items():\n",
    "    name = ticker.replace('^', '')  # Quitar ^ para índices\n",
    "    if ticker in [\"^GSPC\", \"^DJI\", \"^IXIC\"]:\n",
    "        names = {\"^GSPC\": \"S&P_500\", \"^DJI\": \"Dow_Jones\", \"^IXIC\": \"NASDAQ\"}\n",
    "        name = names[ticker]\n",
    "    close_prices[name] = data['Close']\n",
    "\n",
    "# Calcular retornos diarios\n",
    "returns = close_prices.pct_change().dropna()\n",
    "\n",
    "# Calcular matriz de correlación\n",
    "correlation = returns.corr()\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Matriz de Correlación de Retornos Diarios', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis de correlaciones extremas\n",
    "print(\"\\nCorrelaciones más fuertes (positivas):\")\n",
    "corr_pairs = []\n",
    "for i in range(len(correlation.columns)):\n",
    "    for j in range(i+1, len(correlation.columns)):\n",
    "        corr_pairs.append((correlation.columns[i], correlation.columns[j], correlation.iloc[i, j]))\n",
    "\n",
    "# Ordenar por valor absoluto de correlación\n",
    "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "# Mostrar top 5 correlaciones más fuertes\n",
    "for pair in corr_pairs[:5]:\n",
    "    print(f\"{pair[0]} vs {pair[1]}: {pair[2]:.4f}\")\n",
    "\n",
    "# Mostrar correlaciones más débiles\n",
    "print(\"\\nCorrelaciones más débiles:\")\n",
    "for pair in corr_pairs[-5:]:\n",
    "    print(f\"{pair[0]} vs {pair[1]}: {pair[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372c701",
   "metadata": {},
   "source": [
    "## 8. Preparación de Datos para Modelado\n",
    "\n",
    "Crearemos un conjunto de datos estructurado para el modelado predictivo, transformando los datos en un formato adecuado para modelos de series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar un activo para modelado (S&P 500)\n",
    "ticker_model = \"^GSPC\"\n",
    "if ticker_model in data_dict:\n",
    "    # Calcular indicadores\n",
    "    df_model = calculate_indicators(data_dict[ticker_model])\n",
    "    \n",
    "    # Seleccionar características relevantes\n",
    "    features = [\n",
    "        'Close', 'Volume', 'Return', 'SMA_5', 'SMA_20', \n",
    "        'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "        'BB_Upper', 'BB_Lower', 'BB_Width', 'Volatility_20', 'Rel_Volume'\n",
    "    ]\n",
    "    \n",
    "    df_features = df_model[features].copy()\n",
    "    \n",
    "    # Verificar valores nulos\n",
    "    print(\"Valores nulos en el conjunto de datos:\")\n",
    "    display(df_features.isnull().sum())\n",
    "    \n",
    "    # Eliminar filas con valores nulos\n",
    "    df_features = df_features.dropna()\n",
    "    \n",
    "    # Normalizar los datos\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df_features)\n",
    "    \n",
    "    # Crear un DataFrame con datos normalizados\n",
    "    df_scaled = pd.DataFrame(scaled_data, columns=features, index=df_features.index)\n",
    "    \n",
    "    print(\"\\nDatos normalizados:\")\n",
    "    display(df_scaled.head())\n",
    "    \n",
    "    # Función para crear secuencias para entrenamiento\n",
    "    def create_sequences(data, sequence_length=60, target_col='Close'):\n",
    "        X, y = [], []\n",
    "        \n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data.iloc[i:i+sequence_length].values)\n",
    "            y.append(data.iloc[i+sequence_length][target_col])\n",
    "            \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    # Definir longitud de secuencia\n",
    "    seq_length = 20\n",
    "    \n",
    "    # Crear secuencias\n",
    "    X, y = create_sequences(df_scaled, sequence_length=seq_length)\n",
    "    \n",
    "    print(f\"\\nConjunto de datos creado con secuencias de {seq_length} días:\")\n",
    "    print(f\"X shape: {X.shape}\")  # (muestras, seq_length, características)\n",
    "    print(f\"y shape: {y.shape}\")  # (muestras,)\n",
    "    \n",
    "    # Dividir en conjunto de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    print(f\"\\nConjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "    print(f\"Conjunto de prueba: {X_test.shape[0]} muestras\")\n",
    "    \n",
    "    # Guardar datos para uso posterior\n",
    "    np.save('../data/X_train.npy', X_train)\n",
    "    np.save('../data/y_train.npy', y_train)\n",
    "    np.save('../data/X_test.npy', X_test)\n",
    "    np.save('../data/y_test.npy', y_test)\n",
    "    \n",
    "    print(\"\\nDatos preparados y guardados para modelado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71138356",
   "metadata": {},
   "source": [
    "## 9. Visualización de Patrones en los Datos\n",
    "\n",
    "Visualizaremos algunos patrones específicos en los datos que podrían ser útiles para el modelado predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d70b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la distribución de retornos\n",
    "if ticker_model in data_dict:\n",
    "    df = df_model.copy()\n",
    "    \n",
    "    # Crear figura con subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Distribución de retornos diarios\n",
    "    sns.histplot(df['Return'].dropna(), kde=True, ax=axs[0, 0], color='blue')\n",
    "    axs[0, 0].set_title('Distribución de Retornos Diarios (%)', fontsize=14)\n",
    "    axs[0, 0].set_xlabel('Retorno (%)')\n",
    "    axs[0, 0].set_ylabel('Frecuencia')\n",
    "    \n",
    "    # 2. QQ-Plot de retornos (verificar normalidad)\n",
    "    from scipy import stats\n",
    "    stats.probplot(df['Return'].dropna(), dist=\"norm\", plot=axs[0, 1])\n",
    "    axs[0, 1].set_title('QQ-Plot de Retornos Diarios', fontsize=14)\n",
    "    \n",
    "    # 3. Autocorrelación de retornos\n",
    "    from pandas.plotting import autocorrelation_plot\n",
    "    autocorrelation_plot(df['Return'].dropna(), ax=axs[1, 0])\n",
    "    axs[1, 0].set_title('Autocorrelación de Retornos', fontsize=14)\n",
    "    \n",
    "    # 4. Volatilidad vs Retorno\n",
    "    axs[1, 1].scatter(df['Volatility_20'], df['Return'], alpha=0.5, color='purple')\n",
    "    axs[1, 1].set_title('Volatilidad vs Retorno', fontsize=14)\n",
    "    axs[1, 1].set_xlabel('Volatilidad (20 días)')\n",
    "    axs[1, 1].set_ylabel('Retorno (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Graficar la relación entre volumen y retorno\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.scatter(df['Rel_Volume'], df['Return'], alpha=0.5, color='green')\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.title('Relación entre Volumen Relativo y Retorno', fontsize=15)\n",
    "    plt.xlabel('Volumen Relativo (actual / promedio 20 días)')\n",
    "    plt.ylabel('Retorno (%)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce55d8",
   "metadata": {},
   "source": [
    "## 10. Conclusiones y Próximos Pasos\n",
    "\n",
    "Basándonos en el análisis exploratorio, podemos extraer algunas conclusiones importantes y definir los próximos pasos para el modelado predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7960c3",
   "metadata": {},
   "source": [
    "### Conclusiones:\n",
    "\n",
    "1. **Estructura de datos**: Los datos financieros muestran patrones temporales que pueden ser modelados mediante técnicas de series temporales como LSTM o GRU.\n",
    "\n",
    "2. **Indicadores técnicos**: Hemos calculado una amplia gama de indicadores técnicos que pueden servir como características para nuestros modelos predictivos.\n",
    "\n",
    "3. **Correlaciones**: Existe una fuerte correlación entre ciertos activos financieros, lo que puede ser útil para estrategias de diversificación o para predecir el movimiento de un activo basado en otros.\n",
    "\n",
    "4. **Preparación de datos**: Hemos estructurado los datos en secuencias temporales adecuadas para modelos de aprendizaje profundo.\n",
    "\n",
    "### Próximos Pasos:\n",
    "\n",
    "1. **Modelado predictivo**: Desarrollar modelos de series temporales (LSTM, GRU, etc.) para predecir los precios futuros.\n",
    "\n",
    "2. **Evaluación de modelos**: Implementar métricas adecuadas para evaluar el rendimiento de los modelos.\n",
    "\n",
    "3. **Backtesting**: Realizar pruebas retrospectivas de estrategias de trading basadas en las predicciones.\n",
    "\n",
    "4. **Optimización**: Ajustar hiperparámetros y seleccionar las mejores características para mejorar el rendimiento.\n",
    "\n",
    "5. **Implementación**: Desarrollar un sistema automatizado para actualizar datos, reentrenar modelos y generar señales de trading.\n",
    "\n",
    "Los datos preparados en este notebook servirán como base para la implementación de modelos predictivos en el proyecto de trading algorítmico."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
